import os
import cv2
import numpy as np
import tensorflow as tf
from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import google.generativeai as genai  # ì•ˆì •ì ì¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
from dotenv import load_dotenv

# 1. .env íŒŒì¼ ë¡œë“œ
# (ê°™ì€ í´ë”ì— ìˆëŠ” .env íŒŒì¼ì„ ì°¾ì•„ì„œ ì½ì–´ì˜µë‹ˆë‹¤)
load_dotenv()

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ëª¨ë¸ ë¡œë“œ
try:
    MODEL = tf.keras.models.load_model("my_doodle_model_64.h5")
    print("âœ… ëª¨ë¸ ë¡œë”© ì„±ê³µ!")
except Exception as e:
    print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
    MODEL = None

CLASSES = [
    "cat", "dog", "rabbit", "lion", "tiger", "bear",
    "bird", "fish", "penguin", "frog",
    "car", "airplane", "bicycle", "tree", "flower"
]

KOREAN_MAPPING = {
    "cat": "ê³ ì–‘ì´", "dog": "ê°•ì•„ì§€", "rabbit": "í† ë¼", 
    "lion": "ì‚¬ì", "tiger": "í˜¸ë‘ì´", "bear": "ê³°",
    "bird": "ìƒˆ", "fish": "ë¬¼ê³ ê¸°", "penguin": "í­ê·„", "frog": "ê°œêµ¬ë¦¬",
    "car": "ìë™ì°¨", "airplane": "ë¹„í–‰ê¸°", "bicycle": "ìì „ê±°",
    "tree": "ë‚˜ë¬´", "flower": "ê½ƒ"
}

# ==========================================
# ğŸ”‘ API í‚¤ ì„¤ì • (.envì—ì„œ ê°€ì ¸ì˜¤ê¸°)
# ==========================================
MY_API_KEY = os.getenv("GOOGLE_API_KEY")

# í‚¤ê°€ ì˜ ê°€ì ¸ì™€ì¡ŒëŠ”ì§€ í„°ë¯¸ë„ì— ì‚´ì§ ë³´ì—¬ì¤Œ (ë³´ì•ˆìƒ ì• 5ìë¦¬ë§Œ)
if not MY_API_KEY:
    print("âš ï¸ [ê²½ê³ ] .env íŒŒì¼ì„ ëª» ì°¾ê±°ë‚˜ í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤!")
else:
    print(f"ğŸ”‘ API í‚¤ ë¡œë“œ ì„±ê³µ: {MY_API_KEY[:5]}*****")

try:
    genai.configure(api_key=MY_API_KEY)
    gemini_model = genai.GenerativeModel("gemini-2.5-flash")
except Exception as e:
    print(f"âŒ ì„¤ì • ì˜¤ë¥˜: {e}")


def preprocess_image_64(image_bytes):
    nparr = np.frombuffer(image_bytes, np.uint8)
    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    inv_img = 255 - img
    coords = cv2.findNonZero(inv_img)
    if coords is not None:
        x, y, w, h = cv2.boundingRect(coords)
        pad = 20
        x = max(0, x - pad)
        y = max(0, y - pad)
        w = min(img.shape[1] - x, w + 2*pad)
        h = min(img.shape[0] - y, h + 2*pad)
        img = img[y:y+h, x:x+w]

    img = cv2.resize(img, (64, 64), interpolation=cv2.INTER_AREA)
    img = cv2.bitwise_not(img)
    _, img = cv2.threshold(img, 50, 255, cv2.THRESH_BINARY)
    kernel = np.ones((2, 2), np.uint8)
    img = cv2.dilate(img, kernel, iterations=1)
    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    img = img.astype('float32') / 255.0
    img = img.reshape(1, 64, 64, 3)
    return img

class StoryRequest(BaseModel):
    label: str


@app.post("/predict")
async def predict_sketch(file: UploadFile = File(...)):
    if MODEL is None: return {"candidates": []}
    
    contents = await file.read()
    try:
        processed_img = preprocess_image_64(contents)
        pred = MODEL.predict(processed_img)
        
        # 1. ëª¨ë“  í™•ë¥ ì„ ë†’ì€ ìˆœì„œëŒ€ë¡œ ì«˜ë¥´ë¥µ ì¤„ ì„¸ì›ë‹ˆë‹¤.
        # (argsortëŠ” ë‚®ì€ ìˆœ ì •ë ¬ì´ë¼ [::-1]ë¡œ ë’¤ì§‘ì–´ì„œ ë†’ì€ ìˆœìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤)
        sorted_indices = np.argsort(pred[0])[::-1]
        
        candidates = []
        
        # 2. ìˆœì„œëŒ€ë¡œ í•˜ë‚˜ì”© êº¼ë‚´ì„œ ê²€ì‚¬í•©ë‹ˆë‹¤.
        for idx in sorted_indices:
            # ì´ë¯¸ 3ê°œë¥¼ ë‹¤ ì°¾ì•˜ìœ¼ë©´ ê·¸ë§Œ
            if len(candidates) >= 3:
                break
                
            english_label = CLASSES[idx] 
            
            # ê²°ê³¼ê°€ 'ì‚¬ì(lion)'ë¼ë©´ -> ë¬´ì‹œ
            if english_label == "lion":
                continue 

            confidence = float(pred[0][idx]) * 100
            korean_label = KOREAN_MAPPING.get(english_label, english_label)
            
            # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            candidates.append({
                "korean_label": korean_label,
                "confidence": round(confidence, 1)
            })

        return {"candidates": candidates}

    except Exception as e:
        print(f"ì˜ˆì¸¡ ì—ëŸ¬: {e}")
        return {"candidates": []}


@app.post("/generate-story")
async def generate_story(req: StoryRequest):
    print(f"ğŸ“ ë™í™” ìš”ì²­: {req.label}")
    try:
        prompt = f"""
    ë‹¹ì‹ ì€ ë‹¤ì •í•˜ê³  ê°ìˆ˜ì„±ì´ í’ë¶€í•œ ë™í™” ì‘ê°€ì…ë‹ˆë‹¤.
    ì£¼ì œ: '{req.label}'

    1. '**' ê°™ì€ íŠ¹ìˆ˜ê¸°í˜¸ë‚˜ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. (ìˆœìˆ˜í•œ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥)
    2. 'ì œëª©:', 'êµí›ˆ:', 'ë' ê°™ì€ ë”±ë”±í•œ ë¼ë²¨ì„ ì ˆëŒ€ ë¶™ì´ì§€ ë§ˆì„¸ìš”.
    3. êµí›ˆì€ ë§ˆì§€ë§‰ì— ë”°ë¡œ ìš”ì•½í•˜ì§€ ë§ê³ , ì£¼ì¸ê³µì˜ ëŒ€ì‚¬ë‚˜ ì´ì•¼ê¸°ì˜ ë§ˆë¬´ë¦¬ì— ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ë‚´ì„¸ìš”.
    4. ë¬¸ì²´: ë¶€ë“œëŸ¬ìš´ êµ¬ì–´ì²´(ì¡´ëŒ“ë§)ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    5. ë¶„ëŸ‰: 100ì ë‚´ì™¸.
    6. ì½ê¸° ì‰½ê²Œ ë¬¸ë‹¨ì„ ë‚˜ëˆ„ì–´ ì£¼ì„¸ìš”.
    7. í•„ìš”ì‹œ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.
    8. ì£¼ì¸ê³µì—ê²Œ ê·€ì—½ê³  ë©‹ì§€ê³  ì˜ˆìœ ì´ë¦„ì„ ì§€ì–´ì£¼ì„¸ìš”
    """
        
        response = gemini_model.generate_content(prompt)
        print(" ë™í™” ìƒì„± ì„±ê³µ!")
        return {"story": response.text}

    except Exception as e:
        print(f"âŒ [ì—ëŸ¬] AI ì‘ë‹µ ì‹¤íŒ¨: {e}")
        return {"story": f"ë™í™”ë¥¼ ì§“ë‹¤ê°€ ì‹¤ìˆ˜ë¥¼ í–ˆì–´ìš”: {e}"}